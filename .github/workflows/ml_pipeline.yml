name: ML Pipeline CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * 0'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  MLFLOW_TRACKING_URI: 'http://localhost:5000'

jobs:
  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install linting tools
        run: |
          pip install flake8 black isort
      
      - name: Lint with flake8
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics || true
        continue-on-error: true

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-timeout
      
      - name: Run unit tests
        run: |
          pytest tests/ --cov=. --cov-report=xml --cov-report=term-missing --timeout=300 -v
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  preprocess:
    name: Preprocess Data
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create dummy dataset script
        run: |
          cat > create_dataset.py << 'EOF'
          import pandas as pd
          import numpy as np
          import os
          
          if not os.path.exists('E_Commerce_Dataset.xlsx'):
              print('Creating dummy dataset...')
              np.random.seed(42)
              n_samples = 1000
              
              data = {
                  'CustomerID': range(1, n_samples + 1),
                  'Churn': np.random.randint(0, 2, n_samples),
                  'Tenure': np.random.randint(0, 60, n_samples),
                  'PreferredLoginDevice': np.random.choice(['Mobile Phone', 'Computer'], n_samples),
                  'CityTier': np.random.randint(1, 4, n_samples),
                  'WarehouseToHome': np.random.uniform(5, 50, n_samples),
                  'PreferredPaymentMode': np.random.choice(['Credit Card', 'Debit Card', 'Cash on Delivery', 'UPI', 'E wallet'], n_samples),
                  'Gender': np.random.choice(['Male', 'Female'], n_samples),
                  'HourSpendOnApp': np.random.uniform(0, 10, n_samples),
                  'NumberOfDeviceRegistered': np.random.randint(1, 6, n_samples),
                  'PreferedOrderCat': np.random.choice(['Laptop & Accessory', 'Mobile Phone', 'Fashion', 'Grocery', 'Others'], n_samples),
                  'SatisfactionScore': np.random.randint(1, 6, n_samples),
                  'MaritalStatus': np.random.choice(['Single', 'Married', 'Divorced'], n_samples),
                  'NumberOfAddress': np.random.randint(1, 10, n_samples),
                  'Complain': np.random.randint(0, 2, n_samples),
                  'OrderAmountHikeFromlastYear': np.random.uniform(0, 50, n_samples),
                  'CouponUsed': np.random.uniform(0, 10, n_samples),
                  'OrderCount': np.random.uniform(1, 20, n_samples),
                  'DaySinceLastOrder': np.random.uniform(0, 30, n_samples),
                  'CashbackAmount': np.random.uniform(0, 500, n_samples),
              }
              
              df = pd.DataFrame(data)
              df.to_excel('E_Commerce_Dataset.xlsx', sheet_name='E Comm', index=False)
              print('âœ“ Created dummy dataset')
          else:
              print('âœ“ Dataset already exists')
          EOF
      
      - name: Check for dataset
        run: python create_dataset.py
      
      - name: Preprocess data
        run: |
          python preprocess.py --dataset E_Commerce_Dataset.xlsx --clients 3 --output-folder preprocessed_data
      
      - name: Verify preprocessing outputs
        run: |
          echo "Checking preprocessed files..."
          ls -lh preprocessed_data/
          test -f preprocessed_data/preprocessor.pkl || exit 1
          test -f preprocessed_data/metadata.json || exit 1
          echo "âœ“ All preprocessing outputs found"
      
      - name: Upload preprocessed data
        uses: actions/upload-artifact@v3
        with:
          name: preprocessed-data
          path: preprocessed_data/
          retention-days: 7

  train:
    name: Train Model
    runs-on: ubuntu-latest
    needs: preprocess
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Download preprocessed data
        uses: actions/download-artifact@v3
        with:
          name: preprocessed-data
          path: preprocessed_data/
      
      - name: Create dummy dataset script
        run: |
          cat > create_dataset.py << 'EOF'
          import pandas as pd
          import numpy as np
          import os
          
          if not os.path.exists('E_Commerce_Dataset.xlsx'):
              print('Creating dummy dataset...')
              np.random.seed(42)
              n_samples = 1000
              
              data = {
                  'CustomerID': range(1, n_samples + 1),
                  'Churn': np.random.randint(0, 2, n_samples),
                  'Tenure': np.random.randint(0, 60, n_samples),
                  'PreferredLoginDevice': np.random.choice(['Mobile Phone', 'Computer'], n_samples),
                  'CityTier': np.random.randint(1, 4, n_samples),
                  'WarehouseToHome': np.random.uniform(5, 50, n_samples),
                  'PreferredPaymentMode': np.random.choice(['Credit Card', 'Debit Card', 'Cash on Delivery', 'UPI', 'E wallet'], n_samples),
                  'Gender': np.random.choice(['Male', 'Female'], n_samples),
                  'HourSpendOnApp': np.random.uniform(0, 10, n_samples),
                  'NumberOfDeviceRegistered': np.random.randint(1, 6, n_samples),
                  'PreferedOrderCat': np.random.choice(['Laptop & Accessory', 'Mobile Phone', 'Fashion', 'Grocery', 'Others'], n_samples),
                  'SatisfactionScore': np.random.randint(1, 6, n_samples),
                  'MaritalStatus': np.random.choice(['Single', 'Married', 'Divorced'], n_samples),
                  'NumberOfAddress': np.random.randint(1, 10, n_samples),
                  'Complain': np.random.randint(0, 2, n_samples),
                  'OrderAmountHikeFromlastYear': np.random.uniform(0, 50, n_samples),
                  'CouponUsed': np.random.uniform(0, 10, n_samples),
                  'OrderCount': np.random.uniform(1, 20, n_samples),
                  'DaySinceLastOrder': np.random.uniform(0, 30, n_samples),
                  'CashbackAmount': np.random.uniform(0, 500, n_samples),
              }
              
              df = pd.DataFrame(data)
              df.to_excel('E_Commerce_Dataset.xlsx', sheet_name='E Comm', index=False)
              print('âœ“ Created dummy dataset')
          else:
              print('âœ“ Dataset already exists')
          EOF
      
      - name: Check dataset
        run: python create_dataset.py
      
      - name: Start MLflow server
        run: |
          echo "Starting MLflow tracking server..."
          mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns &
          sleep 10
          timeout=60
          elapsed=0
          while ! curl -s http://localhost:5000/health > /dev/null; do
            sleep 2
            elapsed=$((elapsed + 2))
            if [ $elapsed -ge $timeout ]; then
              echo "âŒ MLflow server failed to start"
              exit 1
            fi
            echo "Waiting for MLflow... ($elapsed/$timeout seconds)"
          done
          echo "âœ“ MLflow server is ready"
      
      - name: Train federated model
        run: |
          python training_MLFlow.py --dataset E_Commerce_Dataset.xlsx --num-rounds 10 --batch-size 8
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
        timeout-minutes: 30
      
      - name: Create evaluation script
        run: |
          cat > evaluate_model.py << 'EOF'
          import pandas as pd
          import os
          import sys
          
          metrics_file = 'federated_data/round_evaluation/per_round_metrics.csv'
          
          if not os.path.exists(metrics_file):
              print('âŒ ERROR: Metrics file not found')
              sys.exit(1)
          
          df = pd.read_csv(metrics_file)
          final_metrics = df.iloc[-1]
          
          print('='*60)
          print('FINAL MODEL PERFORMANCE')
          print('='*60)
          print(f'Accuracy:  {final_metrics["eval_accuracy"]:.4f}')
          print(f'Precision: {final_metrics["eval_precision"]:.4f}')
          print(f'Recall:    {final_metrics["eval_recall"]:.4f}')
          print(f'F1 Score:  {final_metrics["eval_f1"]:.4f}')
          print(f'ROC AUC:   {final_metrics["eval_roc_auc"]:.4f}')
          print('='*60)
          
          MIN_ACCURACY = 0.70
          if final_metrics['eval_accuracy'] < MIN_ACCURACY:
              print(f'âŒ Model accuracy ({final_metrics["eval_accuracy"]:.4f}) below threshold ({MIN_ACCURACY})')
              sys.exit(1)
          else:
              print(f'âœ“ Model meets accuracy threshold ({MIN_ACCURACY})')
          
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'accuracy={final_metrics["eval_accuracy"]:.4f}\n')
              f.write(f'f1_score={final_metrics["eval_f1"]:.4f}\n')
          EOF
      
      - name: Evaluate model performance
        id: evaluate
        run: python evaluate_model.py
      
      - name: Create performance summary
        run: |
          echo "## ðŸ“Š Model Training Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Accuracy** | ${{ steps.evaluate.outputs.accuracy }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **F1 Score** | ${{ steps.evaluate.outputs.f1_score }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Model training completed successfully!" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v3
        with:
          name: trained-model
          path: |
            federated_data/federated_churn_model.h5
            federated_data/round_evaluation/
          retention-days: 30
      
      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v3
        with:
          name: mlflow-data
          path: |
            mlruns/
            mlflow.db
          retention-days: 7
        if: always()

  docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: train
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Download model artifacts
        uses: actions/download-artifact@v3
        with:
          name: trained-model
          path: ./
      
      - name: Download preprocessed data
        uses: actions/download-artifact@v3
        with:
          name: preprocessed-data
          path: preprocessed_data/
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Build Docker image
        run: |
          docker build -f Dockerfile.serving -t churn-api:${{ github.sha }} -t churn-api:latest .
      
      - name: Test Docker image
        run: |
          echo "Starting container..."
          docker run -d --name test-api -p 8000:8000 -e MODEL_PATH=/app/model_data/federated_data/federated_churn_model.h5 -e PREPROCESSOR_PATH=/app/model_data/preprocessed_data/preprocessor.pkl churn-api:latest
          timeout=60
          elapsed=0
          while ! curl -s http://localhost:8000/health > /dev/null; do
            sleep 2
            elapsed=$((elapsed + 2))
            if [ $elapsed -ge $timeout ]; then
              echo "âŒ API failed to start"
              docker logs test-api
              exit 1
            fi
            echo "Waiting for API... ($elapsed/$timeout seconds)"
          done
          echo "âœ“ API is running"
          echo "Running health check..."
          curl -f http://localhost:8000/health || exit 1
          echo "Testing prediction endpoint..."
          response=$(curl -s -X POST http://localhost:8000/predict -H "Content-Type: application/json" -d '{"Tenure":12.0,"PreferredLoginDevice":"Mobile Phone","CityTier":1,"WarehouseToHome":15.0,"PreferredPaymentMode":"Credit Card","Gender":"Male","HourSpendOnApp":3.0,"NumberOfDeviceRegistered":3,"PreferedOrderCat":"Laptop & Accessory","SatisfactionScore":5,"MaritalStatus":"Single","NumberOfAddress":2,"Complain":0,"OrderAmountHikeFromlastYear":15.0,"CouponUsed":1.0,"OrderCount":5.0,"DaySinceLastOrder":3.0,"CashbackAmount":150.0}')
          echo "Response: $response"
          if echo "$response" | grep -q "churn_probability"; then
            echo "âœ“ Prediction endpoint working"
          else
            echo "âŒ Prediction endpoint failed"
            exit 1
          fi
          docker stop test-api
          docker rm test-api
      
      - name: Save Docker image
        run: |
          docker save churn-api:latest | gzip > churn-api-latest.tar.gz
      
      - name: Upload Docker image
        uses: actions/upload-artifact@v3
        with:
          name: docker-image
          path: churn-api-latest.tar.gz
          retention-days: 7

  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: docker
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Deployment placeholder
        run: |
          echo "==================================="
          echo "DEPLOYMENT CONFIGURATION"
          echo "==================================="
          echo ""
          echo "To enable production deployment:"
          echo "1. Set up Kubernetes cluster"
          echo "2. Configure kubectl credentials"
          echo "3. Add kubeconfig to GitHub Secrets"
          echo "4. Update this step with actual deployment commands"
          echo ""
          echo "==================================="
      
      - name: Create deployment summary
        run: |
          echo "## ðŸš€ Deployment Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Pipeline completed successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Model trained and evaluated" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Docker image built and tested" >> $GITHUB_STEP_SUMMARY
          echo "- â„¹ï¸ Deployment to production: Manual (placeholder)" >> $GITHUB_STEP_SUMMARY
